{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install -q tensorflow-datasets #Install tensorflow datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds # Import datasets\n",
    "imdb, info = tfds.load(\"imdb_reviews\", with_info = True, as_supervised = True) # inputs data and info data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_data,test_data = imdb['train'],imdb['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sentences =[]\n",
    "training_labels =[]\n",
    "\n",
    "testing_sentences = []\n",
    "testing_labels=[]\n",
    "\n",
    "for s,l in train_data:\n",
    "    training_sentences.append(str(s.numpy())) # To convert the tensors to string value \n",
    "    training_labels.append(l.numpy())\n",
    "    \n",
    "for s,l in test_data:\n",
    "    testing_sentences.append(str(s.numpy()))\n",
    "    testing_labels.append(l.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing the labels to numpy array\n",
    "training_labels_final = np.array(training_labels)\n",
    "testing_labels_final = np.array(testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokening our sentences\n",
    "vocab_size = 10000\n",
    "embedding_dim = 16\n",
    "max_length = 120\n",
    "trunc_type = 'post'\n",
    "oov_tok = \"<OOV>\"\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#Declare Tokenizer\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token = oov_tok)\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "padded = pad_sequences(sequences, maxlen = max_length, truncating = trunc_type)\n",
    "\n",
    "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
    "testing_padded = pad_sequences(testing_sequences,maxlen = max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 120, 16)           160000    \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 11526     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 171,533\n",
      "Trainable params: 171,533\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Defining the neural network\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size,embedding_dim,input_length = max_length),#key to text sentimental analysis in tensorflow\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(6,activation ='relu'),\n",
    "    tf.keras.layers.Dense(1,activation='sigmoid')\n",
    "])\n",
    "model.compile(loss ='binary_crossentropy',optimizer = 'adam',metrics =['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - ETA: 11:18 - loss: 0.6886 - accuracy: 0.593 - ETA: 1:11 - loss: 0.6912 - accuracy: 0.528 - ETA: 46s - loss: 0.6930 - accuracy: 0.5000 - ETA: 31s - loss: 0.6924 - accuracy: 0.502 - ETA: 26s - loss: 0.6923 - accuracy: 0.500 - ETA: 22s - loss: 0.6929 - accuracy: 0.495 - ETA: 18s - loss: 0.6927 - accuracy: 0.506 - ETA: 17s - loss: 0.6924 - accuracy: 0.511 - ETA: 15s - loss: 0.6920 - accuracy: 0.517 - ETA: 14s - loss: 0.6918 - accuracy: 0.521 - ETA: 13s - loss: 0.6918 - accuracy: 0.518 - ETA: 12s - loss: 0.6917 - accuracy: 0.520 - ETA: 11s - loss: 0.6910 - accuracy: 0.525 - ETA: 10s - loss: 0.6911 - accuracy: 0.528 - ETA: 9s - loss: 0.6912 - accuracy: 0.532 - ETA: 9s - loss: 0.6906 - accuracy: 0.53 - ETA: 8s - loss: 0.6905 - accuracy: 0.53 - ETA: 8s - loss: 0.6906 - accuracy: 0.53 - ETA: 7s - loss: 0.6901 - accuracy: 0.54 - ETA: 7s - loss: 0.6898 - accuracy: 0.54 - ETA: 7s - loss: 0.6895 - accuracy: 0.54 - ETA: 6s - loss: 0.6888 - accuracy: 0.55 - ETA: 6s - loss: 0.6881 - accuracy: 0.55 - ETA: 6s - loss: 0.6869 - accuracy: 0.55 - ETA: 6s - loss: 0.6854 - accuracy: 0.56 - ETA: 5s - loss: 0.6833 - accuracy: 0.57 - ETA: 5s - loss: 0.6816 - accuracy: 0.57 - ETA: 5s - loss: 0.6797 - accuracy: 0.57 - ETA: 5s - loss: 0.6775 - accuracy: 0.58 - ETA: 5s - loss: 0.6755 - accuracy: 0.58 - ETA: 5s - loss: 0.6725 - accuracy: 0.59 - ETA: 4s - loss: 0.6693 - accuracy: 0.59 - ETA: 4s - loss: 0.6662 - accuracy: 0.59 - ETA: 4s - loss: 0.6638 - accuracy: 0.60 - ETA: 4s - loss: 0.6610 - accuracy: 0.60 - ETA: 4s - loss: 0.6574 - accuracy: 0.61 - ETA: 4s - loss: 0.6524 - accuracy: 0.61 - ETA: 4s - loss: 0.6479 - accuracy: 0.62 - ETA: 3s - loss: 0.6430 - accuracy: 0.62 - ETA: 3s - loss: 0.6400 - accuracy: 0.62 - ETA: 3s - loss: 0.6350 - accuracy: 0.63 - ETA: 3s - loss: 0.6304 - accuracy: 0.63 - ETA: 3s - loss: 0.6265 - accuracy: 0.64 - ETA: 3s - loss: 0.6219 - accuracy: 0.64 - ETA: 3s - loss: 0.6164 - accuracy: 0.65 - ETA: 3s - loss: 0.6128 - accuracy: 0.65 - ETA: 3s - loss: 0.6107 - accuracy: 0.65 - ETA: 3s - loss: 0.6055 - accuracy: 0.66 - ETA: 2s - loss: 0.6017 - accuracy: 0.66 - ETA: 2s - loss: 0.5975 - accuracy: 0.66 - ETA: 2s - loss: 0.5949 - accuracy: 0.66 - ETA: 2s - loss: 0.5911 - accuracy: 0.67 - ETA: 2s - loss: 0.5881 - accuracy: 0.67 - ETA: 2s - loss: 0.5860 - accuracy: 0.67 - ETA: 2s - loss: 0.5834 - accuracy: 0.67 - ETA: 2s - loss: 0.5804 - accuracy: 0.68 - ETA: 2s - loss: 0.5779 - accuracy: 0.68 - ETA: 2s - loss: 0.5752 - accuracy: 0.68 - ETA: 2s - loss: 0.5723 - accuracy: 0.68 - ETA: 2s - loss: 0.5691 - accuracy: 0.68 - ETA: 2s - loss: 0.5666 - accuracy: 0.68 - ETA: 2s - loss: 0.5649 - accuracy: 0.69 - ETA: 2s - loss: 0.5622 - accuracy: 0.69 - ETA: 1s - loss: 0.5603 - accuracy: 0.69 - ETA: 1s - loss: 0.5584 - accuracy: 0.69 - ETA: 1s - loss: 0.5557 - accuracy: 0.69 - ETA: 1s - loss: 0.5541 - accuracy: 0.69 - ETA: 1s - loss: 0.5517 - accuracy: 0.70 - ETA: 1s - loss: 0.5497 - accuracy: 0.70 - ETA: 1s - loss: 0.5480 - accuracy: 0.70 - ETA: 1s - loss: 0.5458 - accuracy: 0.70 - ETA: 1s - loss: 0.5433 - accuracy: 0.70 - ETA: 1s - loss: 0.5399 - accuracy: 0.70 - ETA: 1s - loss: 0.5368 - accuracy: 0.71 - ETA: 1s - loss: 0.5343 - accuracy: 0.71 - ETA: 1s - loss: 0.5316 - accuracy: 0.71 - ETA: 1s - loss: 0.5295 - accuracy: 0.71 - ETA: 1s - loss: 0.5275 - accuracy: 0.71 - ETA: 0s - loss: 0.5253 - accuracy: 0.72 - ETA: 0s - loss: 0.5231 - accuracy: 0.72 - ETA: 0s - loss: 0.5211 - accuracy: 0.72 - ETA: 0s - loss: 0.5181 - accuracy: 0.72 - ETA: 0s - loss: 0.5159 - accuracy: 0.72 - ETA: 0s - loss: 0.5145 - accuracy: 0.72 - ETA: 0s - loss: 0.5118 - accuracy: 0.73 - ETA: 0s - loss: 0.5099 - accuracy: 0.73 - ETA: 0s - loss: 0.5074 - accuracy: 0.73 - ETA: 0s - loss: 0.5053 - accuracy: 0.73 - ETA: 0s - loss: 0.5032 - accuracy: 0.73 - ETA: 0s - loss: 0.5019 - accuracy: 0.73 - ETA: 0s - loss: 0.5007 - accuracy: 0.73 - ETA: 0s - loss: 0.4988 - accuracy: 0.74 - 8s 308us/sample - loss: 0.4976 - accuracy: 0.7411 - val_loss: 0.3553 - val_accuracy: 0.8422\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - ETA: 4s - loss: 0.3088 - accuracy: 0.84 - ETA: 5s - loss: 0.2912 - accuracy: 0.86 - ETA: 5s - loss: 0.2885 - accuracy: 0.87 - ETA: 5s - loss: 0.2747 - accuracy: 0.88 - ETA: 4s - loss: 0.2691 - accuracy: 0.88 - ETA: 4s - loss: 0.2602 - accuracy: 0.89 - ETA: 4s - loss: 0.2617 - accuracy: 0.89 - ETA: 4s - loss: 0.2599 - accuracy: 0.89 - ETA: 4s - loss: 0.2547 - accuracy: 0.89 - ETA: 4s - loss: 0.2518 - accuracy: 0.89 - ETA: 4s - loss: 0.2454 - accuracy: 0.90 - ETA: 4s - loss: 0.2468 - accuracy: 0.90 - ETA: 4s - loss: 0.2430 - accuracy: 0.90 - ETA: 4s - loss: 0.2418 - accuracy: 0.90 - ETA: 4s - loss: 0.2429 - accuracy: 0.90 - ETA: 4s - loss: 0.2446 - accuracy: 0.90 - ETA: 4s - loss: 0.2483 - accuracy: 0.90 - ETA: 3s - loss: 0.2470 - accuracy: 0.90 - ETA: 3s - loss: 0.2450 - accuracy: 0.90 - ETA: 3s - loss: 0.2457 - accuracy: 0.90 - ETA: 3s - loss: 0.2433 - accuracy: 0.90 - ETA: 3s - loss: 0.2436 - accuracy: 0.90 - ETA: 3s - loss: 0.2443 - accuracy: 0.90 - ETA: 3s - loss: 0.2443 - accuracy: 0.90 - ETA: 3s - loss: 0.2439 - accuracy: 0.90 - ETA: 3s - loss: 0.2448 - accuracy: 0.90 - ETA: 3s - loss: 0.2432 - accuracy: 0.90 - ETA: 3s - loss: 0.2431 - accuracy: 0.90 - ETA: 3s - loss: 0.2435 - accuracy: 0.90 - ETA: 3s - loss: 0.2422 - accuracy: 0.90 - ETA: 3s - loss: 0.2422 - accuracy: 0.90 - ETA: 3s - loss: 0.2420 - accuracy: 0.90 - ETA: 3s - loss: 0.2423 - accuracy: 0.90 - ETA: 3s - loss: 0.2417 - accuracy: 0.90 - ETA: 3s - loss: 0.2408 - accuracy: 0.90 - ETA: 3s - loss: 0.2402 - accuracy: 0.90 - ETA: 2s - loss: 0.2406 - accuracy: 0.90 - ETA: 2s - loss: 0.2401 - accuracy: 0.90 - ETA: 2s - loss: 0.2406 - accuracy: 0.90 - ETA: 2s - loss: 0.2414 - accuracy: 0.90 - ETA: 2s - loss: 0.2411 - accuracy: 0.90 - ETA: 2s - loss: 0.2407 - accuracy: 0.90 - ETA: 2s - loss: 0.2409 - accuracy: 0.90 - ETA: 2s - loss: 0.2421 - accuracy: 0.90 - ETA: 2s - loss: 0.2427 - accuracy: 0.90 - ETA: 2s - loss: 0.2426 - accuracy: 0.90 - ETA: 2s - loss: 0.2421 - accuracy: 0.90 - ETA: 2s - loss: 0.2413 - accuracy: 0.90 - ETA: 2s - loss: 0.2403 - accuracy: 0.90 - ETA: 2s - loss: 0.2406 - accuracy: 0.90 - ETA: 2s - loss: 0.2400 - accuracy: 0.90 - ETA: 2s - loss: 0.2398 - accuracy: 0.90 - ETA: 2s - loss: 0.2409 - accuracy: 0.90 - ETA: 2s - loss: 0.2407 - accuracy: 0.90 - ETA: 2s - loss: 0.2406 - accuracy: 0.90 - ETA: 2s - loss: 0.2410 - accuracy: 0.90 - ETA: 2s - loss: 0.2415 - accuracy: 0.90 - ETA: 2s - loss: 0.2411 - accuracy: 0.90 - ETA: 2s - loss: 0.2407 - accuracy: 0.90 - ETA: 2s - loss: 0.2407 - accuracy: 0.90 - ETA: 2s - loss: 0.2396 - accuracy: 0.90 - ETA: 2s - loss: 0.2394 - accuracy: 0.90 - ETA: 2s - loss: 0.2380 - accuracy: 0.90 - ETA: 2s - loss: 0.2384 - accuracy: 0.90 - ETA: 1s - loss: 0.2375 - accuracy: 0.90 - ETA: 1s - loss: 0.2374 - accuracy: 0.90 - ETA: 1s - loss: 0.2377 - accuracy: 0.90 - ETA: 1s - loss: 0.2378 - accuracy: 0.90 - ETA: 1s - loss: 0.2373 - accuracy: 0.90 - ETA: 1s - loss: 0.2382 - accuracy: 0.90 - ETA: 1s - loss: 0.2383 - accuracy: 0.90 - ETA: 1s - loss: 0.2382 - accuracy: 0.90 - ETA: 1s - loss: 0.2379 - accuracy: 0.90 - ETA: 1s - loss: 0.2373 - accuracy: 0.90 - ETA: 1s - loss: 0.2367 - accuracy: 0.90 - ETA: 1s - loss: 0.2366 - accuracy: 0.90 - ETA: 1s - loss: 0.2364 - accuracy: 0.90 - ETA: 1s - loss: 0.2368 - accuracy: 0.90 - ETA: 1s - loss: 0.2365 - accuracy: 0.90 - ETA: 1s - loss: 0.2367 - accuracy: 0.90 - ETA: 1s - loss: 0.2369 - accuracy: 0.90 - ETA: 0s - loss: 0.2377 - accuracy: 0.90 - ETA: 0s - loss: 0.2379 - accuracy: 0.90 - ETA: 0s - loss: 0.2376 - accuracy: 0.90 - ETA: 0s - loss: 0.2375 - accuracy: 0.90 - ETA: 0s - loss: 0.2376 - accuracy: 0.90 - ETA: 0s - loss: 0.2376 - accuracy: 0.90 - ETA: 0s - loss: 0.2375 - accuracy: 0.90 - ETA: 0s - loss: 0.2375 - accuracy: 0.90 - ETA: 0s - loss: 0.2380 - accuracy: 0.90 - ETA: 0s - loss: 0.2383 - accuracy: 0.90 - ETA: 0s - loss: 0.2385 - accuracy: 0.90 - ETA: 0s - loss: 0.2394 - accuracy: 0.90 - ETA: 0s - loss: 0.2392 - accuracy: 0.90 - ETA: 0s - loss: 0.2391 - accuracy: 0.90 - ETA: 0s - loss: 0.2388 - accuracy: 0.90 - ETA: 0s - loss: 0.2385 - accuracy: 0.90 - ETA: 0s - loss: 0.2383 - accuracy: 0.90 - ETA: 0s - loss: 0.2383 - accuracy: 0.90 - ETA: 0s - loss: 0.2382 - accuracy: 0.90 - 7s 288us/sample - loss: 0.2385 - accuracy: 0.9065 - val_loss: 0.3767 - val_accuracy: 0.8360\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - ETA: 15s - loss: 0.0958 - accuracy: 1.000 - ETA: 8s - loss: 0.1077 - accuracy: 0.982 - ETA: 6s - loss: 0.1076 - accuracy: 0.97 - ETA: 6s - loss: 0.0969 - accuracy: 0.98 - ETA: 5s - loss: 0.0991 - accuracy: 0.98 - ETA: 5s - loss: 0.0961 - accuracy: 0.98 - ETA: 5s - loss: 0.0967 - accuracy: 0.98 - ETA: 5s - loss: 0.0968 - accuracy: 0.98 - ETA: 5s - loss: 0.0955 - accuracy: 0.98 - ETA: 4s - loss: 0.0969 - accuracy: 0.98 - ETA: 4s - loss: 0.0955 - accuracy: 0.98 - ETA: 4s - loss: 0.0948 - accuracy: 0.98 - ETA: 4s - loss: 0.0971 - accuracy: 0.98 - ETA: 4s - loss: 0.0965 - accuracy: 0.98 - ETA: 4s - loss: 0.0983 - accuracy: 0.98 - ETA: 4s - loss: 0.0968 - accuracy: 0.98 - ETA: 4s - loss: 0.0969 - accuracy: 0.98 - ETA: 4s - loss: 0.0950 - accuracy: 0.98 - ETA: 4s - loss: 0.0950 - accuracy: 0.98 - ETA: 4s - loss: 0.0946 - accuracy: 0.98 - ETA: 4s - loss: 0.0938 - accuracy: 0.98 - ETA: 4s - loss: 0.0940 - accuracy: 0.98 - ETA: 4s - loss: 0.0945 - accuracy: 0.98 - ETA: 4s - loss: 0.0950 - accuracy: 0.98 - ETA: 4s - loss: 0.0946 - accuracy: 0.98 - ETA: 4s - loss: 0.0945 - accuracy: 0.98 - ETA: 4s - loss: 0.0932 - accuracy: 0.98 - ETA: 4s - loss: 0.0953 - accuracy: 0.98 - ETA: 4s - loss: 0.0954 - accuracy: 0.98 - ETA: 4s - loss: 0.0947 - accuracy: 0.98 - ETA: 4s - loss: 0.0960 - accuracy: 0.98 - ETA: 4s - loss: 0.0950 - accuracy: 0.98 - ETA: 3s - loss: 0.0941 - accuracy: 0.98 - ETA: 3s - loss: 0.0940 - accuracy: 0.98 - ETA: 3s - loss: 0.0944 - accuracy: 0.98 - ETA: 3s - loss: 0.0934 - accuracy: 0.98 - ETA: 3s - loss: 0.0931 - accuracy: 0.98 - ETA: 3s - loss: 0.0930 - accuracy: 0.98 - ETA: 3s - loss: 0.0930 - accuracy: 0.98 - ETA: 3s - loss: 0.0920 - accuracy: 0.98 - ETA: 3s - loss: 0.0919 - accuracy: 0.98 - ETA: 3s - loss: 0.0916 - accuracy: 0.98 - ETA: 3s - loss: 0.0916 - accuracy: 0.98 - ETA: 3s - loss: 0.0926 - accuracy: 0.97 - ETA: 3s - loss: 0.0924 - accuracy: 0.97 - ETA: 3s - loss: 0.0918 - accuracy: 0.97 - ETA: 2s - loss: 0.0909 - accuracy: 0.98 - ETA: 2s - loss: 0.0913 - accuracy: 0.98 - ETA: 2s - loss: 0.0914 - accuracy: 0.97 - ETA: 2s - loss: 0.0915 - accuracy: 0.97 - ETA: 2s - loss: 0.0910 - accuracy: 0.97 - ETA: 2s - loss: 0.0906 - accuracy: 0.97 - ETA: 2s - loss: 0.0913 - accuracy: 0.97 - ETA: 2s - loss: 0.0913 - accuracy: 0.97 - ETA: 2s - loss: 0.0910 - accuracy: 0.97 - ETA: 2s - loss: 0.0903 - accuracy: 0.97 - ETA: 2s - loss: 0.0898 - accuracy: 0.97 - ETA: 2s - loss: 0.0894 - accuracy: 0.97 - ETA: 2s - loss: 0.0893 - accuracy: 0.97 - ETA: 2s - loss: 0.0894 - accuracy: 0.97 - ETA: 2s - loss: 0.0896 - accuracy: 0.97 - ETA: 1s - loss: 0.0892 - accuracy: 0.97 - ETA: 1s - loss: 0.0884 - accuracy: 0.97 - ETA: 1s - loss: 0.0884 - accuracy: 0.97 - ETA: 1s - loss: 0.0884 - accuracy: 0.97 - ETA: 1s - loss: 0.0882 - accuracy: 0.97 - ETA: 1s - loss: 0.0882 - accuracy: 0.97 - ETA: 1s - loss: 0.0878 - accuracy: 0.97 - ETA: 1s - loss: 0.0879 - accuracy: 0.97 - ETA: 1s - loss: 0.0877 - accuracy: 0.97 - ETA: 1s - loss: 0.0879 - accuracy: 0.97 - ETA: 1s - loss: 0.0876 - accuracy: 0.97 - ETA: 1s - loss: 0.0873 - accuracy: 0.97 - ETA: 1s - loss: 0.0869 - accuracy: 0.97 - ETA: 1s - loss: 0.0865 - accuracy: 0.97 - ETA: 1s - loss: 0.0863 - accuracy: 0.98 - ETA: 1s - loss: 0.0864 - accuracy: 0.98 - ETA: 1s - loss: 0.0863 - accuracy: 0.97 - ETA: 1s - loss: 0.0864 - accuracy: 0.97 - ETA: 0s - loss: 0.0866 - accuracy: 0.97 - ETA: 0s - loss: 0.0868 - accuracy: 0.97 - ETA: 0s - loss: 0.0866 - accuracy: 0.97 - ETA: 0s - loss: 0.0863 - accuracy: 0.97 - ETA: 0s - loss: 0.0856 - accuracy: 0.97 - ETA: 0s - loss: 0.0856 - accuracy: 0.97 - ETA: 0s - loss: 0.0857 - accuracy: 0.97 - ETA: 0s - loss: 0.0856 - accuracy: 0.97 - ETA: 0s - loss: 0.0859 - accuracy: 0.97 - ETA: 0s - loss: 0.0857 - accuracy: 0.97 - ETA: 0s - loss: 0.0856 - accuracy: 0.97 - ETA: 0s - loss: 0.0857 - accuracy: 0.97 - ETA: 0s - loss: 0.0856 - accuracy: 0.97 - ETA: 0s - loss: 0.0858 - accuracy: 0.97 - ETA: 0s - loss: 0.0858 - accuracy: 0.97 - ETA: 0s - loss: 0.0855 - accuracy: 0.97 - ETA: 0s - loss: 0.0855 - accuracy: 0.97 - 7s 286us/sample - loss: 0.0855 - accuracy: 0.9796 - val_loss: 0.4614 - val_accuracy: 0.8252\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - ETA: 6s - loss: 0.0197 - accuracy: 1.00 - ETA: 6s - loss: 0.0356 - accuracy: 0.99 - ETA: 6s - loss: 0.0353 - accuracy: 0.99 - ETA: 5s - loss: 0.0316 - accuracy: 0.99 - ETA: 6s - loss: 0.0333 - accuracy: 0.99 - ETA: 5s - loss: 0.0306 - accuracy: 0.99 - ETA: 5s - loss: 0.0284 - accuracy: 0.99 - ETA: 5s - loss: 0.0267 - accuracy: 0.99 - ETA: 5s - loss: 0.0257 - accuracy: 0.99 - ETA: 5s - loss: 0.0251 - accuracy: 0.99 - ETA: 5s - loss: 0.0243 - accuracy: 0.99 - ETA: 5s - loss: 0.0256 - accuracy: 0.99 - ETA: 5s - loss: 0.0252 - accuracy: 0.99 - ETA: 5s - loss: 0.0272 - accuracy: 0.99 - ETA: 5s - loss: 0.0266 - accuracy: 0.99 - ETA: 5s - loss: 0.0273 - accuracy: 0.99 - ETA: 4s - loss: 0.0263 - accuracy: 0.99 - ETA: 4s - loss: 0.0255 - accuracy: 0.99 - ETA: 4s - loss: 0.0252 - accuracy: 0.99 - ETA: 4s - loss: 0.0248 - accuracy: 0.99 - ETA: 4s - loss: 0.0247 - accuracy: 0.99 - ETA: 4s - loss: 0.0244 - accuracy: 0.99 - ETA: 4s - loss: 0.0239 - accuracy: 0.99 - ETA: 4s - loss: 0.0234 - accuracy: 0.99 - ETA: 4s - loss: 0.0230 - accuracy: 0.99 - ETA: 3s - loss: 0.0229 - accuracy: 0.99 - ETA: 3s - loss: 0.0226 - accuracy: 0.99 - ETA: 3s - loss: 0.0224 - accuracy: 0.99 - ETA: 3s - loss: 0.0222 - accuracy: 0.99 - ETA: 3s - loss: 0.0225 - accuracy: 0.99 - ETA: 3s - loss: 0.0229 - accuracy: 0.99 - ETA: 3s - loss: 0.0229 - accuracy: 0.99 - ETA: 3s - loss: 0.0240 - accuracy: 0.99 - ETA: 3s - loss: 0.0238 - accuracy: 0.99 - ETA: 3s - loss: 0.0240 - accuracy: 0.99 - ETA: 3s - loss: 0.0244 - accuracy: 0.99 - ETA: 3s - loss: 0.0242 - accuracy: 0.99 - ETA: 3s - loss: 0.0252 - accuracy: 0.99 - ETA: 3s - loss: 0.0253 - accuracy: 0.99 - ETA: 3s - loss: 0.0251 - accuracy: 0.99 - ETA: 2s - loss: 0.0249 - accuracy: 0.99 - ETA: 2s - loss: 0.0248 - accuracy: 0.99 - ETA: 2s - loss: 0.0245 - accuracy: 0.99 - ETA: 2s - loss: 0.0244 - accuracy: 0.99 - ETA: 2s - loss: 0.0243 - accuracy: 0.99 - ETA: 2s - loss: 0.0241 - accuracy: 0.99 - ETA: 2s - loss: 0.0243 - accuracy: 0.99 - ETA: 2s - loss: 0.0242 - accuracy: 0.99 - ETA: 2s - loss: 0.0239 - accuracy: 0.99 - ETA: 2s - loss: 0.0237 - accuracy: 0.99 - ETA: 2s - loss: 0.0235 - accuracy: 0.99 - ETA: 2s - loss: 0.0235 - accuracy: 0.99 - ETA: 2s - loss: 0.0234 - accuracy: 0.99 - ETA: 2s - loss: 0.0232 - accuracy: 0.99 - ETA: 2s - loss: 0.0230 - accuracy: 0.99 - ETA: 2s - loss: 0.0229 - accuracy: 0.99 - ETA: 2s - loss: 0.0231 - accuracy: 0.99 - ETA: 1s - loss: 0.0235 - accuracy: 0.99 - ETA: 1s - loss: 0.0237 - accuracy: 0.99 - ETA: 1s - loss: 0.0237 - accuracy: 0.99 - ETA: 1s - loss: 0.0236 - accuracy: 0.99 - ETA: 1s - loss: 0.0235 - accuracy: 0.99 - ETA: 1s - loss: 0.0237 - accuracy: 0.99 - ETA: 1s - loss: 0.0236 - accuracy: 0.99 - ETA: 1s - loss: 0.0234 - accuracy: 0.99 - ETA: 1s - loss: 0.0233 - accuracy: 0.99 - ETA: 1s - loss: 0.0232 - accuracy: 0.99 - ETA: 1s - loss: 0.0230 - accuracy: 0.99 - ETA: 1s - loss: 0.0229 - accuracy: 0.99 - ETA: 1s - loss: 0.0227 - accuracy: 0.99 - ETA: 1s - loss: 0.0226 - accuracy: 0.99 - ETA: 1s - loss: 0.0227 - accuracy: 0.99 - ETA: 1s - loss: 0.0225 - accuracy: 0.99 - ETA: 1s - loss: 0.0226 - accuracy: 0.99 - ETA: 1s - loss: 0.0228 - accuracy: 0.99 - ETA: 1s - loss: 0.0228 - accuracy: 0.99 - ETA: 0s - loss: 0.0228 - accuracy: 0.99 - ETA: 0s - loss: 0.0227 - accuracy: 0.99 - ETA: 0s - loss: 0.0225 - accuracy: 0.99 - ETA: 0s - loss: 0.0224 - accuracy: 0.99 - ETA: 0s - loss: 0.0223 - accuracy: 0.99 - ETA: 0s - loss: 0.0221 - accuracy: 0.99 - ETA: 0s - loss: 0.0220 - accuracy: 0.99 - ETA: 0s - loss: 0.0219 - accuracy: 0.99 - ETA: 0s - loss: 0.0220 - accuracy: 0.99 - ETA: 0s - loss: 0.0219 - accuracy: 0.99 - ETA: 0s - loss: 0.0218 - accuracy: 0.99 - ETA: 0s - loss: 0.0220 - accuracy: 0.99 - ETA: 0s - loss: 0.0222 - accuracy: 0.99 - ETA: 0s - loss: 0.0221 - accuracy: 0.99 - ETA: 0s - loss: 0.0220 - accuracy: 0.99 - ETA: 0s - loss: 0.0221 - accuracy: 0.99 - ETA: 0s - loss: 0.0220 - accuracy: 0.99 - ETA: 0s - loss: 0.0219 - accuracy: 0.99 - 7s 294us/sample - loss: 0.0219 - accuracy: 0.9975 - val_loss: 0.5361 - val_accuracy: 0.8272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "25000/25000 [==============================] - ETA: 6s - loss: 0.0068 - accuracy: 1.00 - ETA: 6s - loss: 0.0061 - accuracy: 1.00 - ETA: 6s - loss: 0.0061 - accuracy: 1.00 - ETA: 6s - loss: 0.0134 - accuracy: 0.99 - ETA: 6s - loss: 0.0116 - accuracy: 0.99 - ETA: 7s - loss: 0.0106 - accuracy: 0.99 - ETA: 6s - loss: 0.0098 - accuracy: 0.99 - ETA: 7s - loss: 0.0093 - accuracy: 0.99 - ETA: 7s - loss: 0.0089 - accuracy: 0.99 - ETA: 7s - loss: 0.0086 - accuracy: 0.99 - ETA: 7s - loss: 0.0112 - accuracy: 0.99 - ETA: 7s - loss: 0.0106 - accuracy: 0.99 - ETA: 6s - loss: 0.0103 - accuracy: 0.99 - ETA: 6s - loss: 0.0098 - accuracy: 0.99 - ETA: 6s - loss: 0.0096 - accuracy: 0.99 - ETA: 6s - loss: 0.0092 - accuracy: 0.99 - ETA: 6s - loss: 0.0089 - accuracy: 0.99 - ETA: 6s - loss: 0.0086 - accuracy: 0.99 - ETA: 6s - loss: 0.0084 - accuracy: 0.99 - ETA: 6s - loss: 0.0083 - accuracy: 0.99 - ETA: 6s - loss: 0.0094 - accuracy: 0.99 - ETA: 6s - loss: 0.0092 - accuracy: 0.99 - ETA: 6s - loss: 0.0090 - accuracy: 0.99 - ETA: 5s - loss: 0.0087 - accuracy: 0.99 - ETA: 5s - loss: 0.0085 - accuracy: 0.99 - ETA: 5s - loss: 0.0082 - accuracy: 0.99 - ETA: 5s - loss: 0.0081 - accuracy: 0.99 - ETA: 5s - loss: 0.0078 - accuracy: 0.99 - ETA: 5s - loss: 0.0077 - accuracy: 0.99 - ETA: 4s - loss: 0.0075 - accuracy: 0.99 - ETA: 4s - loss: 0.0074 - accuracy: 0.99 - ETA: 4s - loss: 0.0073 - accuracy: 0.99 - ETA: 4s - loss: 0.0075 - accuracy: 0.99 - ETA: 4s - loss: 0.0074 - accuracy: 0.99 - ETA: 4s - loss: 0.0074 - accuracy: 0.99 - ETA: 4s - loss: 0.0074 - accuracy: 0.99 - ETA: 4s - loss: 0.0076 - accuracy: 0.99 - ETA: 4s - loss: 0.0076 - accuracy: 0.99 - ETA: 4s - loss: 0.0075 - accuracy: 0.99 - ETA: 3s - loss: 0.0079 - accuracy: 0.99 - ETA: 3s - loss: 0.0078 - accuracy: 0.99 - ETA: 3s - loss: 0.0077 - accuracy: 0.99 - ETA: 3s - loss: 0.0076 - accuracy: 0.99 - ETA: 3s - loss: 0.0075 - accuracy: 0.99 - ETA: 3s - loss: 0.0074 - accuracy: 0.99 - ETA: 3s - loss: 0.0081 - accuracy: 0.99 - ETA: 3s - loss: 0.0080 - accuracy: 0.99 - ETA: 3s - loss: 0.0080 - accuracy: 0.99 - ETA: 3s - loss: 0.0079 - accuracy: 0.99 - ETA: 3s - loss: 0.0078 - accuracy: 0.99 - ETA: 2s - loss: 0.0077 - accuracy: 0.99 - ETA: 2s - loss: 0.0077 - accuracy: 0.99 - ETA: 2s - loss: 0.0076 - accuracy: 0.99 - ETA: 2s - loss: 0.0075 - accuracy: 0.99 - ETA: 2s - loss: 0.0078 - accuracy: 0.99 - ETA: 2s - loss: 0.0083 - accuracy: 0.99 - ETA: 2s - loss: 0.0082 - accuracy: 0.99 - ETA: 2s - loss: 0.0084 - accuracy: 0.99 - ETA: 2s - loss: 0.0084 - accuracy: 0.99 - ETA: 2s - loss: 0.0083 - accuracy: 0.99 - ETA: 2s - loss: 0.0087 - accuracy: 0.99 - ETA: 2s - loss: 0.0086 - accuracy: 0.99 - ETA: 1s - loss: 0.0089 - accuracy: 0.99 - ETA: 1s - loss: 0.0088 - accuracy: 0.99 - ETA: 1s - loss: 0.0087 - accuracy: 0.99 - ETA: 1s - loss: 0.0087 - accuracy: 0.99 - ETA: 1s - loss: 0.0088 - accuracy: 0.99 - ETA: 1s - loss: 0.0088 - accuracy: 0.99 - ETA: 1s - loss: 0.0090 - accuracy: 0.99 - ETA: 1s - loss: 0.0089 - accuracy: 0.99 - ETA: 1s - loss: 0.0088 - accuracy: 0.99 - ETA: 1s - loss: 0.0087 - accuracy: 0.99 - ETA: 1s - loss: 0.0087 - accuracy: 0.99 - ETA: 1s - loss: 0.0086 - accuracy: 0.99 - ETA: 1s - loss: 0.0085 - accuracy: 0.99 - ETA: 1s - loss: 0.0084 - accuracy: 0.99 - ETA: 1s - loss: 0.0084 - accuracy: 0.99 - ETA: 0s - loss: 0.0086 - accuracy: 0.99 - ETA: 0s - loss: 0.0087 - accuracy: 0.99 - ETA: 0s - loss: 0.0087 - accuracy: 0.99 - ETA: 0s - loss: 0.0086 - accuracy: 0.99 - ETA: 0s - loss: 0.0085 - accuracy: 0.99 - ETA: 0s - loss: 0.0085 - accuracy: 0.99 - ETA: 0s - loss: 0.0084 - accuracy: 0.99 - ETA: 0s - loss: 0.0084 - accuracy: 0.99 - ETA: 0s - loss: 0.0083 - accuracy: 0.99 - ETA: 0s - loss: 0.0086 - accuracy: 0.99 - ETA: 0s - loss: 0.0085 - accuracy: 0.99 - ETA: 0s - loss: 0.0085 - accuracy: 0.99 - ETA: 0s - loss: 0.0085 - accuracy: 0.99 - ETA: 0s - loss: 0.0085 - accuracy: 0.99 - ETA: 0s - loss: 0.0084 - accuracy: 0.99 - ETA: 0s - loss: 0.0084 - accuracy: 0.99 - ETA: 0s - loss: 0.0086 - accuracy: 0.99 - ETA: 0s - loss: 0.0086 - accuracy: 0.99 - ETA: 0s - loss: 0.0085 - accuracy: 0.99 - ETA: 0s - loss: 0.0085 - accuracy: 0.99 - 7s 276us/sample - loss: 0.0085 - accuracy: 0.9992 - val_loss: 0.5919 - val_accuracy: 0.8246\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - ETA: 3s - loss: 0.0023 - accuracy: 1.00 - ETA: 4s - loss: 0.0155 - accuracy: 0.99 - ETA: 4s - loss: 0.0092 - accuracy: 0.99 - ETA: 4s - loss: 0.0073 - accuracy: 0.99 - ETA: 4s - loss: 0.0062 - accuracy: 0.99 - ETA: 4s - loss: 0.0055 - accuracy: 0.99 - ETA: 4s - loss: 0.0050 - accuracy: 0.99 - ETA: 3s - loss: 0.0046 - accuracy: 0.99 - ETA: 3s - loss: 0.0043 - accuracy: 0.99 - ETA: 3s - loss: 0.0041 - accuracy: 0.99 - ETA: 3s - loss: 0.0039 - accuracy: 0.99 - ETA: 3s - loss: 0.0038 - accuracy: 0.99 - ETA: 3s - loss: 0.0037 - accuracy: 0.99 - ETA: 3s - loss: 0.0036 - accuracy: 0.99 - ETA: 3s - loss: 0.0035 - accuracy: 0.99 - ETA: 3s - loss: 0.0034 - accuracy: 0.99 - ETA: 3s - loss: 0.0033 - accuracy: 0.99 - ETA: 3s - loss: 0.0032 - accuracy: 0.99 - ETA: 3s - loss: 0.0032 - accuracy: 0.99 - ETA: 3s - loss: 0.0031 - accuracy: 0.99 - ETA: 3s - loss: 0.0031 - accuracy: 0.99 - ETA: 3s - loss: 0.0039 - accuracy: 0.99 - ETA: 3s - loss: 0.0038 - accuracy: 0.99 - ETA: 3s - loss: 0.0037 - accuracy: 0.99 - ETA: 2s - loss: 0.0037 - accuracy: 0.99 - ETA: 2s - loss: 0.0042 - accuracy: 0.99 - ETA: 2s - loss: 0.0041 - accuracy: 0.99 - ETA: 2s - loss: 0.0041 - accuracy: 0.99 - ETA: 2s - loss: 0.0040 - accuracy: 0.99 - ETA: 2s - loss: 0.0040 - accuracy: 0.99 - ETA: 2s - loss: 0.0041 - accuracy: 0.99 - ETA: 2s - loss: 0.0040 - accuracy: 0.99 - ETA: 2s - loss: 0.0040 - accuracy: 0.99 - ETA: 2s - loss: 0.0039 - accuracy: 0.99 - ETA: 2s - loss: 0.0039 - accuracy: 0.99 - ETA: 2s - loss: 0.0038 - accuracy: 0.99 - ETA: 2s - loss: 0.0038 - accuracy: 0.99 - ETA: 2s - loss: 0.0038 - accuracy: 0.99 - ETA: 2s - loss: 0.0041 - accuracy: 0.99 - ETA: 2s - loss: 0.0041 - accuracy: 0.99 - ETA: 2s - loss: 0.0040 - accuracy: 0.99 - ETA: 2s - loss: 0.0040 - accuracy: 0.99 - ETA: 2s - loss: 0.0040 - accuracy: 0.99 - ETA: 2s - loss: 0.0039 - accuracy: 0.99 - ETA: 2s - loss: 0.0043 - accuracy: 0.99 - ETA: 2s - loss: 0.0042 - accuracy: 0.99 - ETA: 1s - loss: 0.0042 - accuracy: 0.99 - ETA: 1s - loss: 0.0042 - accuracy: 0.99 - ETA: 1s - loss: 0.0041 - accuracy: 0.99 - ETA: 1s - loss: 0.0041 - accuracy: 0.99 - ETA: 1s - loss: 0.0040 - accuracy: 0.99 - ETA: 1s - loss: 0.0040 - accuracy: 0.99 - ETA: 1s - loss: 0.0040 - accuracy: 0.99 - ETA: 1s - loss: 0.0039 - accuracy: 0.99 - ETA: 1s - loss: 0.0039 - accuracy: 0.99 - ETA: 1s - loss: 0.0039 - accuracy: 0.99 - ETA: 1s - loss: 0.0038 - accuracy: 0.99 - ETA: 1s - loss: 0.0038 - accuracy: 0.99 - ETA: 1s - loss: 0.0038 - accuracy: 0.99 - ETA: 1s - loss: 0.0037 - accuracy: 0.99 - ETA: 1s - loss: 0.0037 - accuracy: 0.99 - ETA: 1s - loss: 0.0037 - accuracy: 0.99 - ETA: 1s - loss: 0.0037 - accuracy: 0.99 - ETA: 1s - loss: 0.0036 - accuracy: 0.99 - ETA: 1s - loss: 0.0036 - accuracy: 0.99 - ETA: 1s - loss: 0.0036 - accuracy: 0.99 - ETA: 1s - loss: 0.0036 - accuracy: 0.99 - ETA: 1s - loss: 0.0036 - accuracy: 0.99 - ETA: 0s - loss: 0.0035 - accuracy: 0.99 - ETA: 0s - loss: 0.0035 - accuracy: 0.99 - ETA: 0s - loss: 0.0035 - accuracy: 0.99 - ETA: 0s - loss: 0.0035 - accuracy: 0.99 - ETA: 0s - loss: 0.0035 - accuracy: 0.99 - ETA: 0s - loss: 0.0035 - accuracy: 0.99 - ETA: 0s - loss: 0.0034 - accuracy: 0.99 - ETA: 0s - loss: 0.0034 - accuracy: 0.99 - ETA: 0s - loss: 0.0034 - accuracy: 0.99 - ETA: 0s - loss: 0.0034 - accuracy: 0.99 - ETA: 0s - loss: 0.0034 - accuracy: 0.99 - ETA: 0s - loss: 0.0034 - accuracy: 0.99 - ETA: 0s - loss: 0.0034 - accuracy: 0.99 - ETA: 0s - loss: 0.0037 - accuracy: 0.99 - ETA: 0s - loss: 0.0037 - accuracy: 0.99 - ETA: 0s - loss: 0.0037 - accuracy: 0.99 - ETA: 0s - loss: 0.0037 - accuracy: 0.99 - ETA: 0s - loss: 0.0036 - accuracy: 0.99 - ETA: 0s - loss: 0.0036 - accuracy: 0.99 - ETA: 0s - loss: 0.0036 - accuracy: 0.99 - ETA: 0s - loss: 0.0036 - accuracy: 0.99 - 6s 259us/sample - loss: 0.0036 - accuracy: 0.9996 - val_loss: 0.6489 - val_accuracy: 0.8233\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - ETA: 2s - loss: 0.0020 - accuracy: 1.00 - ETA: 3s - loss: 0.0012 - accuracy: 1.00 - ETA: 3s - loss: 0.0012 - accuracy: 1.00 - ETA: 3s - loss: 0.0012 - accuracy: 1.00 - ETA: 3s - loss: 0.0012 - accuracy: 1.00 - ETA: 3s - loss: 0.0012 - accuracy: 1.00 - ETA: 3s - loss: 0.0012 - accuracy: 1.00 - ETA: 3s - loss: 0.0012 - accuracy: 1.00 - ETA: 3s - loss: 0.0012 - accuracy: 1.00 - ETA: 3s - loss: 0.0012 - accuracy: 1.00 - ETA: 4s - loss: 0.0012 - accuracy: 1.00 - ETA: 4s - loss: 0.0012 - accuracy: 1.00 - ETA: 4s - loss: 0.0012 - accuracy: 1.00 - ETA: 3s - loss: 0.0012 - accuracy: 1.00 - ETA: 3s - loss: 0.0012 - accuracy: 1.00 - ETA: 3s - loss: 0.0012 - accuracy: 1.00 - ETA: 3s - loss: 0.0012 - accuracy: 1.00 - ETA: 3s - loss: 0.0012 - accuracy: 1.00 - ETA: 3s - loss: 0.0014 - accuracy: 0.99 - ETA: 3s - loss: 0.0014 - accuracy: 0.99 - ETA: 3s - loss: 0.0014 - accuracy: 0.99 - ETA: 3s - loss: 0.0014 - accuracy: 0.99 - ETA: 3s - loss: 0.0014 - accuracy: 0.99 - ETA: 3s - loss: 0.0014 - accuracy: 0.99 - ETA: 3s - loss: 0.0014 - accuracy: 0.99 - ETA: 3s - loss: 0.0014 - accuracy: 0.99 - ETA: 3s - loss: 0.0013 - accuracy: 0.99 - ETA: 3s - loss: 0.0014 - accuracy: 0.99 - ETA: 3s - loss: 0.0014 - accuracy: 0.99 - ETA: 2s - loss: 0.0014 - accuracy: 0.99 - ETA: 2s - loss: 0.0014 - accuracy: 0.99 - ETA: 2s - loss: 0.0014 - accuracy: 0.99 - ETA: 2s - loss: 0.0014 - accuracy: 0.99 - ETA: 2s - loss: 0.0014 - accuracy: 0.99 - ETA: 2s - loss: 0.0014 - accuracy: 0.99 - ETA: 2s - loss: 0.0014 - accuracy: 0.99 - ETA: 2s - loss: 0.0014 - accuracy: 0.99 - ETA: 2s - loss: 0.0014 - accuracy: 0.99 - ETA: 2s - loss: 0.0015 - accuracy: 0.99 - ETA: 2s - loss: 0.0014 - accuracy: 0.99 - ETA: 2s - loss: 0.0014 - accuracy: 0.99 - ETA: 2s - loss: 0.0014 - accuracy: 0.99 - ETA: 2s - loss: 0.0014 - accuracy: 0.99 - ETA: 2s - loss: 0.0014 - accuracy: 0.99 - ETA: 2s - loss: 0.0014 - accuracy: 0.99 - ETA: 2s - loss: 0.0014 - accuracy: 0.99 - ETA: 1s - loss: 0.0014 - accuracy: 0.99 - ETA: 1s - loss: 0.0014 - accuracy: 0.99 - ETA: 1s - loss: 0.0014 - accuracy: 0.99 - ETA: 1s - loss: 0.0014 - accuracy: 0.99 - ETA: 1s - loss: 0.0013 - accuracy: 0.99 - ETA: 1s - loss: 0.0013 - accuracy: 0.99 - ETA: 1s - loss: 0.0013 - accuracy: 0.99 - ETA: 1s - loss: 0.0013 - accuracy: 0.99 - ETA: 1s - loss: 0.0013 - accuracy: 0.99 - ETA: 1s - loss: 0.0013 - accuracy: 0.99 - ETA: 1s - loss: 0.0013 - accuracy: 0.99 - ETA: 1s - loss: 0.0013 - accuracy: 0.99 - ETA: 1s - loss: 0.0013 - accuracy: 0.99 - ETA: 1s - loss: 0.0013 - accuracy: 0.99 - ETA: 1s - loss: 0.0013 - accuracy: 0.99 - ETA: 1s - loss: 0.0013 - accuracy: 0.99 - ETA: 1s - loss: 0.0013 - accuracy: 0.99 - ETA: 1s - loss: 0.0013 - accuracy: 0.99 - ETA: 1s - loss: 0.0013 - accuracy: 0.99 - ETA: 0s - loss: 0.0013 - accuracy: 0.99 - ETA: 0s - loss: 0.0013 - accuracy: 0.99 - ETA: 0s - loss: 0.0013 - accuracy: 0.99 - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - ETA: 0s - loss: 0.0014 - accuracy: 0.99 - ETA: 0s - loss: 0.0014 - accuracy: 0.99 - ETA: 0s - loss: 0.0015 - accuracy: 0.99 - ETA: 0s - loss: 0.0015 - accuracy: 0.99 - ETA: 0s - loss: 0.0015 - accuracy: 0.99 - ETA: 0s - loss: 0.0015 - accuracy: 0.99 - ETA: 0s - loss: 0.0015 - accuracy: 0.99 - ETA: 0s - loss: 0.0015 - accuracy: 0.99 - ETA: 0s - loss: 0.0015 - accuracy: 0.99 - ETA: 0s - loss: 0.0015 - accuracy: 0.99 - ETA: 0s - loss: 0.0015 - accuracy: 0.99 - ETA: 0s - loss: 0.0015 - accuracy: 0.99 - ETA: 0s - loss: 0.0015 - accuracy: 0.99 - 7s 264us/sample - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.7048 - val_accuracy: 0.8231\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - ETA: 4s - loss: 3.0646e-04 - accuracy: 1.00 - ETA: 4s - loss: 5.8877e-04 - accuracy: 1.00 - ETA: 4s - loss: 6.2476e-04 - accuracy: 1.00 - ETA: 4s - loss: 6.1438e-04 - accuracy: 1.00 - ETA: 4s - loss: 6.2829e-04 - accuracy: 1.00 - ETA: 4s - loss: 6.1581e-04 - accuracy: 1.00 - ETA: 4s - loss: 6.2066e-04 - accuracy: 1.00 - ETA: 4s - loss: 6.2335e-04 - accuracy: 1.00 - ETA: 4s - loss: 6.2227e-04 - accuracy: 1.00 - ETA: 4s - loss: 6.1665e-04 - accuracy: 1.00 - ETA: 4s - loss: 6.1757e-04 - accuracy: 1.00 - ETA: 4s - loss: 6.1675e-04 - accuracy: 1.00 - ETA: 4s - loss: 6.3439e-04 - accuracy: 1.00 - ETA: 4s - loss: 6.3457e-04 - accuracy: 1.00 - ETA: 4s - loss: 6.3178e-04 - accuracy: 1.00 - ETA: 4s - loss: 6.2643e-04 - accuracy: 1.00 - ETA: 4s - loss: 6.2558e-04 - accuracy: 1.00 - ETA: 4s - loss: 6.2827e-04 - accuracy: 1.00 - ETA: 4s - loss: 6.2424e-04 - accuracy: 1.00 - ETA: 4s - loss: 6.2042e-04 - accuracy: 1.00 - ETA: 4s - loss: 6.1937e-04 - accuracy: 1.00 - ETA: 4s - loss: 6.1950e-04 - accuracy: 1.00 - ETA: 4s - loss: 6.1582e-04 - accuracy: 1.00 - ETA: 4s - loss: 6.0840e-04 - accuracy: 1.00 - ETA: 4s - loss: 6.0755e-04 - accuracy: 1.00 - ETA: 4s - loss: 6.0382e-04 - accuracy: 1.00 - ETA: 4s - loss: 6.0121e-04 - accuracy: 1.00 - ETA: 3s - loss: 6.0007e-04 - accuracy: 1.00 - ETA: 3s - loss: 6.0143e-04 - accuracy: 1.00 - ETA: 3s - loss: 6.0082e-04 - accuracy: 1.00 - ETA: 3s - loss: 6.0596e-04 - accuracy: 1.00 - ETA: 3s - loss: 6.0231e-04 - accuracy: 1.00 - ETA: 3s - loss: 6.0337e-04 - accuracy: 1.00 - ETA: 3s - loss: 6.0035e-04 - accuracy: 1.00 - ETA: 3s - loss: 5.9632e-04 - accuracy: 1.00 - ETA: 3s - loss: 5.9643e-04 - accuracy: 1.00 - ETA: 3s - loss: 5.9636e-04 - accuracy: 1.00 - ETA: 3s - loss: 5.9370e-04 - accuracy: 1.00 - ETA: 3s - loss: 5.9426e-04 - accuracy: 1.00 - ETA: 3s - loss: 5.9282e-04 - accuracy: 1.00 - ETA: 3s - loss: 5.9006e-04 - accuracy: 1.00 - ETA: 3s - loss: 5.8758e-04 - accuracy: 1.00 - ETA: 3s - loss: 5.8872e-04 - accuracy: 1.00 - ETA: 3s - loss: 5.9120e-04 - accuracy: 1.00 - ETA: 2s - loss: 5.8901e-04 - accuracy: 1.00 - ETA: 2s - loss: 5.8598e-04 - accuracy: 1.00 - ETA: 2s - loss: 5.8295e-04 - accuracy: 1.00 - ETA: 2s - loss: 5.8336e-04 - accuracy: 1.00 - ETA: 2s - loss: 5.8186e-04 - accuracy: 1.00 - ETA: 2s - loss: 5.8024e-04 - accuracy: 1.00 - ETA: 2s - loss: 5.7806e-04 - accuracy: 1.00 - ETA: 2s - loss: 5.7558e-04 - accuracy: 1.00 - ETA: 2s - loss: 5.7377e-04 - accuracy: 1.00 - ETA: 2s - loss: 5.7269e-04 - accuracy: 1.00 - ETA: 2s - loss: 5.7046e-04 - accuracy: 1.00 - ETA: 2s - loss: 5.6847e-04 - accuracy: 1.00 - ETA: 2s - loss: 5.6924e-04 - accuracy: 1.00 - ETA: 2s - loss: 5.6659e-04 - accuracy: 1.00 - ETA: 2s - loss: 5.6661e-04 - accuracy: 1.00 - ETA: 2s - loss: 5.6328e-04 - accuracy: 1.00 - ETA: 2s - loss: 5.6043e-04 - accuracy: 1.00 - ETA: 2s - loss: 5.5934e-04 - accuracy: 1.00 - ETA: 1s - loss: 5.5954e-04 - accuracy: 1.00 - ETA: 1s - loss: 5.5620e-04 - accuracy: 1.00 - ETA: 1s - loss: 5.5446e-04 - accuracy: 1.00 - ETA: 1s - loss: 5.5277e-04 - accuracy: 1.00 - ETA: 1s - loss: 5.5125e-04 - accuracy: 1.00 - ETA: 1s - loss: 5.5150e-04 - accuracy: 1.00 - ETA: 1s - loss: 5.4850e-04 - accuracy: 1.00 - ETA: 1s - loss: 5.4827e-04 - accuracy: 1.00 - ETA: 1s - loss: 5.4900e-04 - accuracy: 1.00 - ETA: 1s - loss: 5.4722e-04 - accuracy: 1.00 - ETA: 1s - loss: 5.4714e-04 - accuracy: 1.00 - ETA: 1s - loss: 5.4790e-04 - accuracy: 1.00 - ETA: 1s - loss: 5.4608e-04 - accuracy: 1.00 - ETA: 1s - loss: 5.4541e-04 - accuracy: 1.00 - ETA: 1s - loss: 5.4329e-04 - accuracy: 1.00 - ETA: 1s - loss: 5.4212e-04 - accuracy: 1.00 - ETA: 0s - loss: 5.4220e-04 - accuracy: 1.00 - ETA: 0s - loss: 5.4056e-04 - accuracy: 1.00 - ETA: 0s - loss: 5.4076e-04 - accuracy: 1.00 - ETA: 0s - loss: 5.3873e-04 - accuracy: 1.00 - ETA: 0s - loss: 5.3809e-04 - accuracy: 1.00 - ETA: 0s - loss: 5.3590e-04 - accuracy: 1.00 - ETA: 0s - loss: 5.3398e-04 - accuracy: 1.00 - ETA: 0s - loss: 5.3240e-04 - accuracy: 1.00 - ETA: 0s - loss: 5.3133e-04 - accuracy: 1.00 - ETA: 0s - loss: 5.2929e-04 - accuracy: 1.00 - ETA: 0s - loss: 5.2892e-04 - accuracy: 1.00 - ETA: 0s - loss: 5.2784e-04 - accuracy: 1.00 - ETA: 0s - loss: 5.2697e-04 - accuracy: 1.00 - ETA: 0s - loss: 5.2580e-04 - accuracy: 1.00 - ETA: 0s - loss: 5.2582e-04 - accuracy: 1.00 - ETA: 0s - loss: 5.2455e-04 - accuracy: 1.00 - ETA: 0s - loss: 5.2284e-04 - accuracy: 1.00 - 7s 279us/sample - loss: 5.2243e-04 - accuracy: 1.0000 - val_loss: 0.7463 - val_accuracy: 0.8239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "25000/25000 [==============================] - ETA: 5s - loss: 2.2029e-04 - accuracy: 1.00 - ETA: 5s - loss: 2.6604e-04 - accuracy: 1.00 - ETA: 6s - loss: 2.7694e-04 - accuracy: 1.00 - ETA: 6s - loss: 2.7626e-04 - accuracy: 1.00 - ETA: 6s - loss: 2.7701e-04 - accuracy: 1.00 - ETA: 6s - loss: 2.8797e-04 - accuracy: 1.00 - ETA: 6s - loss: 2.9110e-04 - accuracy: 1.00 - ETA: 6s - loss: 2.9957e-04 - accuracy: 1.00 - ETA: 6s - loss: 3.0182e-04 - accuracy: 1.00 - ETA: 6s - loss: 2.9784e-04 - accuracy: 1.00 - ETA: 6s - loss: 3.0289e-04 - accuracy: 1.00 - ETA: 6s - loss: 3.0227e-04 - accuracy: 1.00 - ETA: 5s - loss: 3.0110e-04 - accuracy: 1.00 - ETA: 5s - loss: 3.0040e-04 - accuracy: 1.00 - ETA: 5s - loss: 2.9956e-04 - accuracy: 1.00 - ETA: 4s - loss: 2.9834e-04 - accuracy: 1.00 - ETA: 4s - loss: 2.9913e-04 - accuracy: 1.00 - ETA: 4s - loss: 2.9741e-04 - accuracy: 1.00 - ETA: 4s - loss: 2.9527e-04 - accuracy: 1.00 - ETA: 4s - loss: 2.9270e-04 - accuracy: 1.00 - ETA: 4s - loss: 2.9500e-04 - accuracy: 1.00 - ETA: 4s - loss: 2.9434e-04 - accuracy: 1.00 - ETA: 4s - loss: 2.9377e-04 - accuracy: 1.00 - ETA: 4s - loss: 2.9444e-04 - accuracy: 1.00 - ETA: 4s - loss: 2.9558e-04 - accuracy: 1.00 - ETA: 4s - loss: 2.9335e-04 - accuracy: 1.00 - ETA: 4s - loss: 2.9253e-04 - accuracy: 1.00 - ETA: 3s - loss: 2.9140e-04 - accuracy: 1.00 - ETA: 3s - loss: 2.8995e-04 - accuracy: 1.00 - ETA: 3s - loss: 2.8895e-04 - accuracy: 1.00 - ETA: 3s - loss: 2.8738e-04 - accuracy: 1.00 - ETA: 3s - loss: 2.8685e-04 - accuracy: 1.00 - ETA: 3s - loss: 2.8578e-04 - accuracy: 1.00 - ETA: 3s - loss: 2.8366e-04 - accuracy: 1.00 - ETA: 3s - loss: 2.8296e-04 - accuracy: 1.00 - ETA: 3s - loss: 2.8302e-04 - accuracy: 1.00 - ETA: 3s - loss: 2.8382e-04 - accuracy: 1.00 - ETA: 3s - loss: 2.8580e-04 - accuracy: 1.00 - ETA: 3s - loss: 2.8649e-04 - accuracy: 1.00 - ETA: 3s - loss: 2.8651e-04 - accuracy: 1.00 - ETA: 3s - loss: 2.8710e-04 - accuracy: 1.00 - ETA: 3s - loss: 2.8597e-04 - accuracy: 1.00 - ETA: 3s - loss: 2.8443e-04 - accuracy: 1.00 - ETA: 3s - loss: 2.8295e-04 - accuracy: 1.00 - ETA: 3s - loss: 2.8261e-04 - accuracy: 1.00 - ETA: 2s - loss: 2.8260e-04 - accuracy: 1.00 - ETA: 2s - loss: 2.8282e-04 - accuracy: 1.00 - ETA: 2s - loss: 2.8637e-04 - accuracy: 1.00 - ETA: 2s - loss: 2.8602e-04 - accuracy: 1.00 - ETA: 2s - loss: 2.8606e-04 - accuracy: 1.00 - ETA: 2s - loss: 2.8642e-04 - accuracy: 1.00 - ETA: 2s - loss: 2.8657e-04 - accuracy: 1.00 - ETA: 2s - loss: 2.8574e-04 - accuracy: 1.00 - ETA: 2s - loss: 2.8660e-04 - accuracy: 1.00 - ETA: 2s - loss: 2.8684e-04 - accuracy: 1.00 - ETA: 2s - loss: 2.8647e-04 - accuracy: 1.00 - ETA: 2s - loss: 2.8634e-04 - accuracy: 1.00 - ETA: 2s - loss: 2.8602e-04 - accuracy: 1.00 - ETA: 2s - loss: 2.8558e-04 - accuracy: 1.00 - ETA: 2s - loss: 2.8579e-04 - accuracy: 1.00 - ETA: 2s - loss: 2.8546e-04 - accuracy: 1.00 - ETA: 2s - loss: 2.8537e-04 - accuracy: 1.00 - ETA: 2s - loss: 2.8445e-04 - accuracy: 1.00 - ETA: 1s - loss: 2.8384e-04 - accuracy: 1.00 - ETA: 1s - loss: 2.8338e-04 - accuracy: 1.00 - ETA: 1s - loss: 2.8382e-04 - accuracy: 1.00 - ETA: 1s - loss: 2.8341e-04 - accuracy: 1.00 - ETA: 1s - loss: 2.8388e-04 - accuracy: 1.00 - ETA: 1s - loss: 2.8362e-04 - accuracy: 1.00 - ETA: 1s - loss: 2.8277e-04 - accuracy: 1.00 - ETA: 1s - loss: 2.8195e-04 - accuracy: 1.00 - ETA: 1s - loss: 2.8222e-04 - accuracy: 1.00 - ETA: 1s - loss: 2.8227e-04 - accuracy: 1.00 - ETA: 1s - loss: 2.8164e-04 - accuracy: 1.00 - ETA: 1s - loss: 2.8084e-04 - accuracy: 1.00 - ETA: 1s - loss: 2.8029e-04 - accuracy: 1.00 - ETA: 1s - loss: 2.8101e-04 - accuracy: 1.00 - ETA: 0s - loss: 2.8126e-04 - accuracy: 1.00 - ETA: 0s - loss: 2.8062e-04 - accuracy: 1.00 - ETA: 0s - loss: 2.7961e-04 - accuracy: 1.00 - ETA: 0s - loss: 2.7871e-04 - accuracy: 1.00 - ETA: 0s - loss: 2.7742e-04 - accuracy: 1.00 - ETA: 0s - loss: 2.7678e-04 - accuracy: 1.00 - ETA: 0s - loss: 2.7661e-04 - accuracy: 1.00 - ETA: 0s - loss: 2.7580e-04 - accuracy: 1.00 - ETA: 0s - loss: 2.7557e-04 - accuracy: 1.00 - ETA: 0s - loss: 2.7444e-04 - accuracy: 1.00 - ETA: 0s - loss: 2.7356e-04 - accuracy: 1.00 - ETA: 0s - loss: 2.7288e-04 - accuracy: 1.00 - ETA: 0s - loss: 2.7276e-04 - accuracy: 1.00 - ETA: 0s - loss: 2.7214e-04 - accuracy: 1.00 - ETA: 0s - loss: 2.7218e-04 - accuracy: 1.00 - ETA: 0s - loss: 2.7160e-04 - accuracy: 1.00 - 7s 286us/sample - loss: 2.7134e-04 - accuracy: 1.0000 - val_loss: 0.7807 - val_accuracy: 0.8243\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - ETA: 6s - loss: 1.9343e-04 - accuracy: 1.00 - ETA: 6s - loss: 1.8695e-04 - accuracy: 1.00 - ETA: 6s - loss: 1.8294e-04 - accuracy: 1.00 - ETA: 6s - loss: 1.9931e-04 - accuracy: 1.00 - ETA: 6s - loss: 1.8636e-04 - accuracy: 1.00 - ETA: 5s - loss: 1.8472e-04 - accuracy: 1.00 - ETA: 5s - loss: 1.8835e-04 - accuracy: 1.00 - ETA: 5s - loss: 1.8478e-04 - accuracy: 1.00 - ETA: 5s - loss: 1.8871e-04 - accuracy: 1.00 - ETA: 5s - loss: 1.8623e-04 - accuracy: 1.00 - ETA: 5s - loss: 1.9186e-04 - accuracy: 1.00 - ETA: 5s - loss: 1.9114e-04 - accuracy: 1.00 - ETA: 5s - loss: 1.9091e-04 - accuracy: 1.00 - ETA: 5s - loss: 1.8957e-04 - accuracy: 1.00 - ETA: 5s - loss: 1.8840e-04 - accuracy: 1.00 - ETA: 4s - loss: 1.8641e-04 - accuracy: 1.00 - ETA: 4s - loss: 1.8637e-04 - accuracy: 1.00 - ETA: 4s - loss: 1.8555e-04 - accuracy: 1.00 - ETA: 4s - loss: 1.8350e-04 - accuracy: 1.00 - ETA: 4s - loss: 1.8199e-04 - accuracy: 1.00 - ETA: 4s - loss: 1.8034e-04 - accuracy: 1.00 - ETA: 4s - loss: 1.8091e-04 - accuracy: 1.00 - ETA: 4s - loss: 1.8131e-04 - accuracy: 1.00 - ETA: 3s - loss: 1.8131e-04 - accuracy: 1.00 - ETA: 3s - loss: 1.8059e-04 - accuracy: 1.00 - ETA: 3s - loss: 1.8003e-04 - accuracy: 1.00 - ETA: 3s - loss: 1.7771e-04 - accuracy: 1.00 - ETA: 3s - loss: 1.7772e-04 - accuracy: 1.00 - ETA: 3s - loss: 1.7809e-04 - accuracy: 1.00 - ETA: 3s - loss: 1.7863e-04 - accuracy: 1.00 - ETA: 3s - loss: 1.7782e-04 - accuracy: 1.00 - ETA: 3s - loss: 1.7800e-04 - accuracy: 1.00 - ETA: 3s - loss: 1.7745e-04 - accuracy: 1.00 - ETA: 3s - loss: 1.7641e-04 - accuracy: 1.00 - ETA: 3s - loss: 1.7511e-04 - accuracy: 1.00 - ETA: 3s - loss: 1.7438e-04 - accuracy: 1.00 - ETA: 2s - loss: 1.7407e-04 - accuracy: 1.00 - ETA: 2s - loss: 1.7418e-04 - accuracy: 1.00 - ETA: 2s - loss: 1.7377e-04 - accuracy: 1.00 - ETA: 2s - loss: 1.7463e-04 - accuracy: 1.00 - ETA: 2s - loss: 1.7416e-04 - accuracy: 1.00 - ETA: 2s - loss: 1.7350e-04 - accuracy: 1.00 - ETA: 2s - loss: 1.7334e-04 - accuracy: 1.00 - ETA: 2s - loss: 1.7297e-04 - accuracy: 1.00 - ETA: 2s - loss: 1.7293e-04 - accuracy: 1.00 - ETA: 2s - loss: 1.7207e-04 - accuracy: 1.00 - ETA: 2s - loss: 1.7168e-04 - accuracy: 1.00 - ETA: 2s - loss: 1.7212e-04 - accuracy: 1.00 - ETA: 2s - loss: 1.7213e-04 - accuracy: 1.00 - ETA: 2s - loss: 1.7241e-04 - accuracy: 1.00 - ETA: 2s - loss: 1.7188e-04 - accuracy: 1.00 - ETA: 2s - loss: 1.7167e-04 - accuracy: 1.00 - ETA: 1s - loss: 1.7119e-04 - accuracy: 1.00 - ETA: 1s - loss: 1.7080e-04 - accuracy: 1.00 - ETA: 1s - loss: 1.7037e-04 - accuracy: 1.00 - ETA: 1s - loss: 1.7032e-04 - accuracy: 1.00 - ETA: 1s - loss: 1.6979e-04 - accuracy: 1.00 - ETA: 1s - loss: 1.6968e-04 - accuracy: 1.00 - ETA: 1s - loss: 1.6970e-04 - accuracy: 1.00 - ETA: 1s - loss: 1.6930e-04 - accuracy: 1.00 - ETA: 1s - loss: 1.6907e-04 - accuracy: 1.00 - ETA: 1s - loss: 1.6963e-04 - accuracy: 1.00 - ETA: 1s - loss: 1.6923e-04 - accuracy: 1.00 - ETA: 1s - loss: 1.6921e-04 - accuracy: 1.00 - ETA: 1s - loss: 1.6925e-04 - accuracy: 1.00 - ETA: 1s - loss: 1.6874e-04 - accuracy: 1.00 - ETA: 1s - loss: 1.6838e-04 - accuracy: 1.00 - ETA: 1s - loss: 1.6780e-04 - accuracy: 1.00 - ETA: 1s - loss: 1.6731e-04 - accuracy: 1.00 - ETA: 1s - loss: 1.6662e-04 - accuracy: 1.00 - ETA: 0s - loss: 1.6623e-04 - accuracy: 1.00 - ETA: 0s - loss: 1.6597e-04 - accuracy: 1.00 - ETA: 0s - loss: 1.6549e-04 - accuracy: 1.00 - ETA: 0s - loss: 1.6529e-04 - accuracy: 1.00 - ETA: 0s - loss: 1.6475e-04 - accuracy: 1.00 - ETA: 0s - loss: 1.6430e-04 - accuracy: 1.00 - ETA: 0s - loss: 1.6399e-04 - accuracy: 1.00 - ETA: 0s - loss: 1.6390e-04 - accuracy: 1.00 - ETA: 0s - loss: 1.6354e-04 - accuracy: 1.00 - ETA: 0s - loss: 1.6308e-04 - accuracy: 1.00 - ETA: 0s - loss: 1.6242e-04 - accuracy: 1.00 - ETA: 0s - loss: 1.6230e-04 - accuracy: 1.00 - ETA: 0s - loss: 1.6186e-04 - accuracy: 1.00 - ETA: 0s - loss: 1.6215e-04 - accuracy: 1.00 - ETA: 0s - loss: 1.6151e-04 - accuracy: 1.00 - ETA: 0s - loss: 1.6122e-04 - accuracy: 1.00 - ETA: 0s - loss: 1.6070e-04 - accuracy: 1.00 - ETA: 0s - loss: 1.6054e-04 - accuracy: 1.00 - 7s 268us/sample - loss: 1.6054e-04 - accuracy: 1.0000 - val_loss: 0.8156 - val_accuracy: 0.8244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d516950cc8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the model\n",
    "num_epochs = 10\n",
    "model.fit(padded,training_labels_final,epochs = num_epochs,validation_data =(testing_padded,testing_labels_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "e = model.layers[0]\n",
    "weights = e.get_weights()[0]\n",
    "print(weights.shape) #shape : (vocab_size,embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot it we need to have reversed index so that we can get the to token back to words we need reverse function\n",
    "reversed_word_index = dict([(value,key) for (key,value) in word_index.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "out_v = io.open('vecs.tsv','w', encoding='utf-8')\n",
    "out_m = io.open('meta.tsv','w', encoding='utf-8')\n",
    "for word_num in range(1,vocab_size):\n",
    "    word = reversed_word_index[word_num]\n",
    "    embeddings = weights[word_num]\n",
    "    out_m.write(word+\"\\n\")\n",
    "    out_v.write('\\t'.join([str(x) for x in embeddings])+\"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
